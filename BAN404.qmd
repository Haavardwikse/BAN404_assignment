---
title: "BAN404 - Mandatory"
output: html_document
toc: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = F)
```

## Nessesary libraries

```{r, eval=T, error=TRUE, message=TRUE}
#| warning: false
# Loading necessary libraries
library(Ecdat)       # For the Wages dataset
library(ggplot2)     # For data visualization
library(dplyr)       # For data manipulation
library(caret)       # For data splitting, training, and cross-validation
library(glmnet)      # For Ridge regression and LASSO
library(mgcv)        # For generalized additive models (GAM)
library(rpart)       # For regression trees
library(rpart.plot)  # For plotting regression trees
library(MASS)        # For linear discriminant analysis (LDA)
library(randomForest) # For random forest models, optional for advanced analysis
library(patchwork)

```


# Problem 1

## a)

```{r, eval=T, error=TRUE, message=TRUE}


# Load the Wages dataset
data(Wages)

# Explore the structure of the dataset to identify potential predictors
str(Wages)

# List of predictors you want to plot against lwage
selected_predictors1 <- c( "smsa", "married", "sex", "union", "black")
selected_predictors2 <- c("exp", "wks", "bluecol", "ind", "south")
# "exp", "wks", "bluecol", "ind", "south", "smsa", "married", "sex", "union", "black"

plots_list1 <- list()
plots_list2 <- list()

for(predictor in selected_predictors1) {
  plots_list1[[predictor]] <- ggplot(Wages, aes(x = !!sym(predictor), y = lwage)) +
    geom_point(alpha=0.2) +
    geom_smooth(method="lm", se=FALSE, color="blue") +
    labs(title=paste("lwage vs.", predictor), x=predictor, y="Log Wage")
}

for(predictor in selected_predictors2) {
  plots_list2[[predictor]] <- ggplot(Wages, aes(x = !!sym(predictor), y = lwage)) +
    geom_point(alpha=0.2) +
    geom_smooth(method="lm", se=FALSE, color="blue") +
    labs(title=paste("lwage vs.", predictor), x=predictor, y="Log Wage")
}

# Combine and display the plots
combined_plot1 <- wrap_plots(plots_list1, ncol = 3)
combined_plot2 <- wrap_plots(plots_list2, ncol = 3)

# Display the combined plots
combined_plot1
combined_plot2

# Choose predictors "exp", "wks", "bluecol", "ind", "south", "smsa", "married", "sex", "union", "black"
selected_predictors <- c( "exp", "bluecol", "smsa", "married", "sex", "black")

# Dynamically build the formula with polynomial terms for 'exp' and 'ed'
formula_str <- paste("lwage ~", paste(selected_predictors, collapse=" + "))

# Convert string to formula
formula <- as.formula(formula_str)

# Fit the linear regression model with polynomial terms
model <- lm(formula, data=Wages)
summary(model)


# Interpret the model output
# Look at the coefficients to understand the effect of each predictor on lwage
# Pay special attention to the predictors with non-linear terms (e.g., I(predictor1^2))
# Assess the model's overall fit (e.g., R-squared) and individual predictors' significance (p-values)


```
The linear regression model demonstrates that experience, blue-collar job status, living in an SMSA, marital status, gender, and race significantly impact the logarithm of wages. Specifically, experience, being in an SMSA, and being married are associated with higher wages, while being in a blue-collar job or being black is linked to lower wages. Gender also plays a crucial role, with males earning significantly more than females, all else being equal. Although the model explains about 31.82% of the variability in log wages, suggesting it captures key factors affecting wages, there remains a substantial portion of the variability unexplained, indicating potential for model improvement or the existence of other influential factors not included in the model.

## b)

The prediction model, with a Multiple R-squared of 0.3182, indicates that it can explain a moderate proportion of the variance in logarithmic wages based on the predictors used, though a significant amount of variability remains unaccounted for. The Residual Standard Error (RSE) of 0.3814 points to the average deviation of the observed values from the fitted values, suggesting the model's predictions are reasonably close to the actual data, but there's room for improvement. The significant p-values for all predictors confirm their relevance in explaining wage differences, ensuring that the model's insights are statistically robust. However, to enhance predictive accuracy and account for more variance in wages, exploring additional predictors, interaction terms, or non-linear relationships could be beneficial.


## c)

This R function f implements a basic version of the k-Nearest Neighbors (k-NN) algorithm for regression. Here's a line-by-line explanation:

f=function(x0,x,y,K=20): Defines a function f with inputs x0 (a new data point for which we want to predict the outcome), x (the matrix of features for the training data), y (the vector of outcomes for the training data), and K=20 (the number of nearest neighbors to consider, with a default value of 20).

n <- nrow(x): Determines the number of observations in the training data by counting the rows in x.

p <- ncol(x): Determines the number of features (predictors) in the training data by counting the columns in x.

d <- matrix(0,n,1): Initializes a matrix d with n rows and 1 column filled with zeros. This is a placeholder for the distances between the new data point x0 and each point in the training data x.

d <- sqrt(apply((x-matrix(x0,n,p,byrow=TRUE))^2,1,sum)): Calculates the Euclidean distance between x0 and each observation in x. This is done by subtracting x0 from each row in x (broadcasting x0 across n rows), squaring the differences, summing these squared differences across columns (apply(...,1,sum)), and taking the square root of these sums.

o <- order(d)[1:K]: Orders the distances d in ascending order and selects the indices of the K smallest distances. These indices correspond to the K nearest neighbors of x0 in the training data.

ypred <- mean(y[o]): Calculates the mean outcome y of the K nearest neighbors identified in the previous step. This mean value serves as the prediction for the new data point x0.

return(ypred): Returns the predicted outcome for the new data point x0.

In summary, this function implements the k-Nearest Neighbors algorithm for regression, predicting the outcome for a new observation based on the average outcome of its K nearest neighbors in the feature space.


## d)

```{r, eval=T, error=TRUE, message=TRUE}

# Correcting the function f
f <- function(x0, x, y, K = 20) {
  n <- nrow(x)
  p <- ncol(x)
  d <- matrix(0, n, 1)
  d <- sqrt(apply((x - matrix(x0, n, p, byrow = TRUE))^2, 1, sum))
  o <- order(d)[1:K]
  ypred <- mean(y[o])
  return(ypred)
}

# Encoding 'sex' as a numeric variable where male = 1 and female = 0
Wages$sex_numeric <- ifelse(Wages$sex == "male", 1, 0)

# Splitting the dataset into training and test sets
set.seed(123) # For reproducibility
indices <- sample(1:nrow(Wages), size = 0.8 * nrow(Wages), replace = FALSE) # 80% for training
train_data <- Wages[indices, ]
test_data <- Wages[-indices, ]

# Extracting the chosen predictors ('sex_numeric' and 'ed') and the target variable
x_train <- as.matrix(train_data[, c("sex_numeric", "ed")])
y_train <- train_data$lwage

x_test <- as.matrix(test_data[, c("sex_numeric", "ed")])
y_test <- test_data$lwage

# Initialize vectors to store predictions
predictions_k10 <- numeric(length(y_test))
predictions_k20 <- numeric(length(y_test))

# Loop over the test set for K = 10 and K = 20
for (i in 1:nrow(x_test)) {
  predictions_k10[i] <- f(x0 = x_test[i, ], x = x_train, y = y_train, K = 10)
  predictions_k20[i] <- f(x0 = x_test[i, ], x = x_train, y = y_train, K = 20)
}

# Evaluate the predictions using Mean Squared Error (MSE)
mse_k10 <- mean((predictions_k10 - y_test)^2)
mse_k20 <- mean((predictions_k20 - y_test)^2)

print(paste("MSE for K=10:", mse_k10))
print(paste("MSE for K=20:", mse_k20))


```

## e)

```{r, eval=T, error=TRUE, message=TRUE}

# Define a function for k-fold cross-validation on the k-NN model
cross_validate_knn <- function(K, folds, x, y) {
  fold_size <- nrow(x) / folds
  mse_list <- numeric(folds)
  
  for (i in 1:folds) {
    # Define indices for the validation set
    val_indices <- (((i - 1) * fold_size + 1):(i * fold_size))
    
    # Split the data into training and validation sets
    x_train_cv <- x[-val_indices, ]
    y_train_cv <- y[-val_indices]
    x_val_cv <- x[val_indices, ]
    y_val_cv <- y[val_indices]
    
    # Predict using the current value of K
    predictions <- sapply(1:nrow(x_val_cv), function(j) f(x0 = x_val_cv[j, ], x = x_train_cv, y = y_train_cv, K = K))
    
    # Calculate MSE for the current fold and store it
    mse_list[i] <- mean((predictions - y_val_cv)^2)
  }
  
  # Return the average MSE across all folds
  return(mean(mse_list))
}

# Range of K values to test
K_values <- seq(15, 30, by = 2)  # Testing K values from 1 to 30, skipping by 2
folds <- 3  # Number of folds in k-fold cross-validation

# Prepare the matrix of predictors and the target variable from the training data
x_train_cv <- as.matrix(train_data[, c("sex_numeric", "ed")])
y_train_cv <- train_data$lwage

# Calculate average MSE for each K
mse_results <- sapply(K_values, function(K) cross_validate_knn(K, folds, x_train_cv, y_train_cv))

# Identify the optimal K with the lowest MSE
optimal_K <- K_values[which.min(mse_results)]
optimal_MSE <- min(mse_results)

print(paste("Optimal K:", optimal_K))
print(paste("Optimal MSE:", optimal_MSE))

# You can then use this optimal K to make predictions and evaluate them as before




```

## f)

```{r, eval=T, error=TRUE, message=TRUE}

# Assuming 'train_data' and 'test_data' are already defined
x_train <- as.matrix(train_data[, c("sex_numeric", "ed")])
y_train <- train_data$lwage

x_test <- as.matrix(test_data[, c("sex_numeric", "ed")])
y_test <- test_data$lwage

# For LASSO
set.seed(123) # For reproducibility
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1)

# For Ridge Regression
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0)

# Predictions for LASSO
predictions_lasso <- predict(cv_lasso, newx = x_test, s = "lambda.min")

# Predictions for Ridge
predictions_ridge <- predict(cv_ridge, newx = x_test, s = "lambda.min")

# Calculate MSE
mse_lasso <- mean((predictions_lasso - y_test)^2)
mse_ridge <- mean((predictions_ridge - y_test)^2)

print(paste("LASSO MSE:", mse_lasso))
print(paste("Ridge MSE:", mse_ridge))

```

## g)

```{r, eval=T, error=TRUE, message=TRUE}

# Fit the GAM
gam_model <- gam(lwage ~ s(ed) + sex_numeric, data = train_data)

# Summary of the model
summary(gam_model)

# Make predictions on the test set
predictions_gam <- predict(gam_model, newdata = test_data)

# Calculate MSE
mse_gam <- mean((predictions_gam - test_data$lwage)^2)

print(paste("GAM MSE:", mse_gam))



```

## h)

```{r, eval=T, error=TRUE, message=TRUE}

# Using 'lwage' as the response variable and 'sex_numeric' and 'ed' as predictors
tree_model <- rpart(lwage ~ sex_numeric + ed, data=train_data, method="anova")


rpart.plot(tree_model, type=4, extra=101)

# Making predictions on the test set
predictions_tree <- predict(tree_model, newdata=test_data)

# Evaluate the predictions, e.g., using Mean Squared Error (MSE)
mse_tree <- mean((predictions_tree - test_data$lwage)^2)
print(paste("MSE for the tree:", mse_tree))

# Prune the tree
pruned_tree <- prune(tree_model, cp=tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"])

# Plot the pruned tree
rpart.plot(pruned_tree, type=4, extra=101)

# Evaluate the pruned tree's predictions
predictions_pruned <- predict(pruned_tree, newdata=test_data)
mse_pruned <- mean((predictions_pruned - test_data$lwage)^2)
print(paste("MSE for the pruned tree:", mse_pruned))



```

# Problem 2

## a)

```{r, eval=T, error=TRUE, message=TRUE}
# Determine the 75th percentile of lwage (log wage)
lwage_75th_percentile <- quantile(Wages$lwage, 0.75)

# Create a new binary variable indicating whether an individual is in the top 25% of earners
Wages$top_25_earner <- ifelse(Wages$lwage > lwage_75th_percentile, 1, 0)

Wages %>% glimpse()
```


## b)

```{r, eval=T, error=TRUE, message=TRUE}
# Continuous variables
continuous_vars <- c("exp", "wks", "ed")
# Categorical variables
categorical_vars <- c("bluecol", "ind", "south", "smsa", "married", "sex", "union", "black")

# Initialize an empty list to store plots for continuous and categorical variables
plots_list_continuous <- list()
plots_list_categorical <- list()

# Generate plots for continuous variables
for(var in continuous_vars) {
  plots_list_continuous[[var]] <- ggplot(Wages, aes(x = as.factor(top_25_earner), y = .data[[var]])) +
    geom_boxplot() +
    labs(title = paste(var, "by Top 25% Earners"), x = "Top 25% Earner", y = var)
}

# Generate plots for categorical variables
for(var in categorical_vars) {
  plots_list_categorical[[var]] <- ggplot(Wages, aes(x = .data[[var]], fill = as.factor(top_25_earner))) +
    geom_bar(position = "fill") +
    labs(title = paste("Proportion of Top 25% Earners by", var), x = var, y = "Proportion") +
    scale_fill_manual(values = c("gray", "blue"), labels = c("Not Top 25% Earner", "Top 25% Earner"))
}

# Combine and display the plots for continuous variables
combined_plot_continuous <- wrap_plots(plots_list_continuous, ncol = 3)
combined_plot_continuous

# Combine and display the plots for categorical variables
combined_plot_categorical <- wrap_plots(plots_list_categorical, ncol = 3)
combined_plot_categorical

```

When analyzing binary variables, I consider the proportion differences between top 25% earners and non-top 25% earners for each variable. When analyzing binary variables, I consider the proportion differences between top 25% earners and non-top 25% earners for each variable. Predictors, where one of the categories has a much higher or lower proportion of top earners, could be more informative.
By analyzing the plots, I want to move forward with the following predictors: 
bluecol
married
sex
black
Ed
Exp

## c)

```{r, eval=T, error=TRUE, message=TRUE}
set.seed(123) # For reproducibility

# Splitting the data into training and test sets
splitIndex <- createDataPartition(Wages$top_25_earner, p = .8, list = FALSE, times = 1)
trainData <- Wages[splitIndex,]
testData <- Wages[-splitIndex,]

# Define the formula for the logistic regression model
formula <- as.formula("top_25_earner ~ bluecol + married + sex + black + ed + exp")

# Fit a logistic regression model using the defined formula
logitModel <- glm(formula, data = trainData, family = "binomial")
summary(logitModel)

# Predict on the test set
predicted_probs <- predict(logitModel, newdata = testData, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)

# Evaluate the model
confusionMatrix <- table(Predicted = predicted_classes, Actual = testData$top_25_earner)
print(confusionMatrix)

# Calculate accuracy
accuracy <- sum(diag(confusionMatrix)) / sum(confusionMatrix)
print(paste("Accuracy:", accuracy))

TP_logit <- confusionMatrix[2, 2]
FP_logit <- confusionMatrix[1, 2]
FN_logit <- confusionMatrix[2, 1]
TN_logit <- confusionMatrix[1, 1]

precision_logit <- TP_logit / (TP_logit + FP_logit)
recall_logit <- TP_logit / (TP_logit + FN_logit)
f1_score_logit <- 2 * (precision_logit * recall_logit) / (precision_logit + recall_logit)

cat("Logistic Regression - Precision:", precision_logit, "Recall:", recall_logit, "F1 Score:", f1_score_logit, "\n")


```

The model efficiently identifies people not in the top 25% of earners. Although the model's accuracy is approximately 75.75%, which gives a general idea of its performance, it only partially represents its effectiveness, especially in the case of an imbalanced dataset. While the model shows a reasonable ability to detect non-top 25% earners (as indicated by a high number of true negatives), its precision is relatively low, which suggests a challenge in identifying the top 25% earners accurately without mistakenly classifying non-top 25% earners as being in the top quartile. The recall rate indicates that the model is better at capturing actual top 25% earners, but the balance between precision and recall shows that there is still room for improvement. Therefore, even though the model efficiently determines non-top 25% earners, it needs improvement in accurately identifying the top 25% earners.

## d)

```{r, eval=T, error=TRUE, message=TRUE}
library(MASS) # For lda function

# Assuming testData and trainData from previous step are still valid
# Perform Linear Discriminant Analysis
ldaModel <- lda(formula, data = trainData)

# Predict on the test set
ldaPred <- predict(ldaModel, newdata = testData)
predicted_classes_lda <- ldaPred$class

# Evaluate the model
confusionMatrixLDA <- table(Predicted = predicted_classes_lda, Actual = testData$top_25_earner)
print(confusionMatrixLDA)

# Calculate accuracy
accuracyLDA <- sum(diag(confusionMatrixLDA)) / sum(confusionMatrixLDA)
print(paste("LDA Accuracy:", accuracyLDA))

TP_lda <- confusionMatrixLDA[2, 2]
FP_lda <- confusionMatrixLDA[1, 2]
FN_lda <- confusionMatrixLDA[2, 1]
TN_lda <- confusionMatrixLDA[1, 1]

precision_lda <- TP_lda / (TP_lda + FP_lda)
recall_lda <- TP_lda / (TP_lda + FN_lda)
f1_score_lda <- 2 * (precision_lda * recall_lda) / (precision_lda + recall_lda)

cat("LDA - Precision:", precision_lda, "Recall:", recall_lda, "F1 Score:", f1_score_lda, "\n")

comparison_table <- data.frame(
  Model = c("Logistic Regression", "LDA"),
  accuracy = c(accuracy, accuracyLDA),
  Precision = c(precision_logit, precision_lda),
  Recall = c(recall_logit, recall_lda),
  F1_Score = c(f1_score_logit, f1_score_lda)
)

# Print the comparison table
print(comparison_table)

```

The table presented above displays the outcome of the LDA prediction and compares it with logistic regression. In comparison to logistic regression, we observe slightly adverse marginal effects. All measures of accuracy, precision, recall, and F1 score have decreased.

The decrease in these metrics for LDA suggests that, overall, it is performing slightly worse than Logistic Regression on this dataset. However, the differences are marginal, which means that in this specific case, both models are comparable in predicting the top 25% of earners, with Logistic Regression having a slight edge.

LDA assumes that the predictor variables are normally distributed, have the same variance-covariance matrix across each group, have a linear relationship with the discriminant function, are statistically independent of each other, and the dependent variable is categorical and discrete. LDA also requires an adequate sample size, absence of outliers, and linearity between the means of different groups.
In some instances, the underlying assumptions are not properly met, which is the cause of the lesser performance. 

## e)

```{r, eval=T, error=TRUE, message=TRUE}
library(rpart)       # For building the classification tree
library(rpart.plot)  # For plotting the tree

# Fit a classification tree model
treeModel <- rpart(formula, data = trainData, method = "class")

# Plot the tree
rpart.plot(treeModel, main = "Classification Tree for Top 25% Earners", type = 4, extra = 101)

# Predict on the test set
treePred <- predict(treeModel, newdata = testData, type = "class")

# Evaluate the model
confusionMatrixTree <- table(Predicted = treePred, Actual = testData$top_25_earner)
print(confusionMatrixTree)

# Calculate accuracy
accuracyTree <- sum(diag(confusionMatrixTree)) / sum(confusionMatrixTree)
print(paste("Tree Accuracy:", accuracyTree))

```

The classification tree visually represents the decision rules inferred from the data. The nodes represent the points where the dataset is split based on the values of the predictor variables:

The root node (the topmost node) splits on the 'ed' variable, representing individuals' education levels. If an individual's education level is less than 14 years, they are more likely not to be among the top 25% earners (as seen in the large proportion of the class labeled '0' in this node).

Following the tree to the right, if an individual has 14 or more years of education, further splits are done based on 'exp' (years of experience), 'sex', and 'blue col' (whether they are blue-collar workers), each refining the classification of an individual as a top 25% earner or not.

The leaf nodes (the bottom nodes) show the classification outcomes with the proportion of observations in each class. For example, one of the leaf nodes indicates that males with more than 17 years of experience and less than 38 years of experience, who are not blue-collar workers, are predicted to be top 25% earners.


#### Session info

Leave this part unchanged. The cell below prints which packages and versions were used for creating the html-file. 

```{r, eval=T}
sessionInfo()
```
